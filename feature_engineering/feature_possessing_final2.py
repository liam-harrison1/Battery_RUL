# -*- coding: utf-8 -*-
"""
å…¥æ¨¡å‰å‡†å¤‡ + æ¯ç”µæ± ç‹¬ç«‹ç­›é€‰ + é¢‘æ¬¡ç»Ÿè®¡ï¼ˆMean-Deviation + Null-Importance + Spearmanï¼‰
- è¾“å…¥ï¼šCOMBINED_DIR ä¸‹çš„ *_combined_features.csvï¼ˆæ¯ç”µæ± /æ¯å¾ªç¯ä¸€è¡Œï¼‰
- è¿‡ç¨‹ï¼š
  1) ä»…åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆ MinMaxï¼›å¯¹ train/val/test å…¨é‡åº”ç”¨ï¼›
  2) å¯¹è®­ç»ƒé›†æ¯ä¸ª battery_id ç‹¬ç«‹æ‰§è¡Œä¸‰æ­¥ç­›é€‰ï¼ˆMDâ†’NIâ†’Spearmanï¼‰ï¼Œäº§å‡ºæ¯ç”µæ± ç‰¹å¾ç™½åå•ï¼›
  3) å¯¹æ‰€æœ‰è®­ç»ƒç”µæ± çš„ç™½åå•åšâ€œå‡ºç°é¢‘æ¬¡â€ç»Ÿè®¡ï¼›è‹¥å‡ºç°å¹¶åˆ—ï¼Œç”¨å„ç”µæ±  Spearman çš„ |rho| å¹³å‡å€¼æ‰“ç ´ï¼›
  4) é€‰å‡ºè®ºæ–‡å¼â€œå…¨å±€æœ€ç»ˆç‰¹å¾â€ Top-Kï¼ˆé»˜è®¤ 16ï¼‰ï¼›
  5) ä»…ä¿ç•™è¿™äº›å…¨å±€æœ€ç»ˆç‰¹å¾ï¼Œå¯¼å‡º tabular_train/val/test.csvï¼›
  6) è¾“å‡ºä¸è®ºæ–‡é£æ ¼ä¸€è‡´çš„å›¾ï¼š
     - FigAï¼šç‰¹å¾å‡ºç°é¢‘æ¬¡æ¡å½¢å›¾ï¼ˆTop-Nï¼Œé»‘ç™½é£æ ¼ï¼ŒTimes New Romanï¼‰ï¼›
     - FigBï¼šç”µæ± Ã—ç‰¹å¾ 0/1 é€‰æ‹©çŸ©é˜µï¼ˆç°åº¦çƒ­å›¾ï¼‰ã€‚
- è¾“å‡ºï¼š
  OUT_DIR/
    â”œâ”€â”€ tabular_train.csv / tabular_val.csv / tabular_test.csv
    â”œâ”€â”€ minmax_scaler.json
    â”œâ”€â”€ features_selected_per_battery.json
    â”œâ”€â”€ features_final_global.json
    â”œâ”€â”€ reports/
    â”‚     â”œâ”€â”€ {battery_id}_null_importance.csv
    â”‚     â””â”€â”€ {battery_id}_spearman.csv
    â””â”€â”€ figs/
          â”œâ”€â”€ feature_frequency_bar.png
          â””â”€â”€ selection_matrix_heatmap.png

âš ï¸ ä¾èµ–ï¼špandas, numpy, scipy, lightgbm, matplotlib
LightGBM 4.x æ³¨æ„ï¼šæ—  verbose_evalï¼Œéœ€ç”¨ callbacks æ§åˆ¶æ—¥å¿—æ˜¾ç¤ºã€‚
"""

import os, re, json, random, gc
from typing import List, Dict, Tuple

import numpy as np
import pandas as pd
from scipy.stats import spearmanr
import lightgbm as lgb
import matplotlib as mpl
mpl.use("Agg")  # åç«¯æ— æ˜¾ç¤ºç¯å¢ƒä¹Ÿèƒ½ä¿å­˜å›¾
import matplotlib.pyplot as plt

# ================== å¯é…ç½®åŒºåŸŸ ==================
COMBINED_DIR = r"C:\Users\13512\Desktop\features_mixed"   # è¾“å…¥ç›®å½•
OUT_DIR      = r"C:\Users\13512\Desktop\final_dataset_pro"  # è¾“å‡ºç›®å½•

SEED         = 42

# å‡å€¼åå·®åˆç­›é˜ˆå€¼ï¼ˆåœ¨ MinMax ä¹‹åï¼‰
MD_THRESHOLD = 1e-8

# Null-importance å‚æ•°ï¼ˆå»ºè®®æ¯”æ—§è„šæœ¬æ›´ä¸¥æ ¼ï¼Œè´´è¿‘è®ºæ–‡ï¼‰
N_REAL_RUNS      = 20     # çœŸæ ‡ç­¾è·‘å‡ æ¬¡
N_NULL_RUNS      = 20     # ä¹±åºæ ‡ç­¾è·‘å‡ æ¬¡
NUM_BOOST_ROUND  = 600    # æ¯æ¬¡ LightGBM è¿­ä»£è½®æ•°

LGB_PARAMS = dict(
    objective="regression",
    metric="mae",
    learning_rate=0.03,
    num_leaves=64,
    min_data_in_leaf=40,
    feature_fraction=0.8,
    bagging_fraction=0.8,
    bagging_freq=1,
    lambda_l1=0.0,
    lambda_l2=1.0,
    max_depth=-1,
    verbosity=-1,
    num_threads=0  # 0=å°½å¯èƒ½å¤šæ ¸ï¼›å¦‚éœ€é™æ ¸ï¼Œæ”¹æˆå…·ä½“æ•°å­—
)

# Spearmanï¼šåœ¨æ¯ç”µæ± å†…çš„ NI é€šè¿‡åˆ—é‡Œï¼ŒæŒ‰ |rho| æ’åºï¼›å¯é€‰ Top-K æˆ–åˆ†ä½æˆªæ–­
SPEARMAN_KEEP_TOPK      = 999999      # è‹¥æƒ³åˆ†ä½æˆªæ–­ï¼Œè®¾å¾ˆå¤§ï¼›
SPEARMAN_KEEP_QUANTILE  = 0.50        # ç•™ä¸­ä½æ•°åŠä»¥ä¸Šï¼ˆé…åˆä¸Šé¢å‚æ•°ä½¿ç”¨ï¼‰

# è®ºæ–‡å¼â€œæœ€ç»ˆå…¨å±€ç‰¹å¾â€ä¸ªæ•°
FINAL_TOP_K = 16

# å›¾è¡¨é£æ ¼ï¼ˆå°½å¯èƒ½è´´è¿‘è®ºæ–‡ï¼šé»‘ç™½ã€ç»†çº¿ã€Times New Romanï¼‰
FIG_FONT_FAMILY = "Times New Roman"
FIG_DPI        = 300
FIG_W_SINGLE   = 3.4   # å•æ å®½ï¼ˆè‹±å¯¸ï¼Œ~8.6cmï¼‰
FIG_H_BAR      = 2.2
FIG_H_HEAT     = 3.2

# =================================================

# ---------- å°å·¥å…· ----------
def list_csv(folder: str) -> List[str]:
    return [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith('.csv')]

def extract_battery_id_from_combined(fp: str) -> str:
    """ä»æ–‡ä»¶åæå– battery_idï¼Œä¾‹å¦‚ B0005_combined_features.csv â†’ B0005"""
    base = os.path.basename(fp)
    m = re.match(r"(.+?)_combined_features\.csv$", base)
    return m.group(1) if m else os.path.splitext(base)[0]

# ---------- æ•°æ®è¯»å– ----------
def load_all_combined(combined_dir: str) -> pd.DataFrame:
    rows = []
    for fp in list_csv(combined_dir):
        if not fp.endswith("_combined_features.csv"):
            continue
        bid = extract_battery_id_from_combined(fp)
        df = pd.read_csv(fp)
        if 'cycle_index' not in df.columns:
            raise ValueError(f"{fp} ç¼ºå°‘ cycle_index åˆ—")
        df.insert(0, 'battery_id', bid)
        rows.append(df)
    if not rows:
        raise RuntimeError("æœªåœ¨ COMBINED_DIR ä¸­æ‰¾åˆ° *_combined_features.csv")
    all_df = pd.concat(rows, axis=0, ignore_index=True)
    # åªä¿ç•™æ•°å€¼åˆ— + ä¸»é”®
    keep = ['battery_id', 'cycle_index'] + [
        c for c in all_df.columns
        if c not in ('battery_id', 'cycle_index') and np.issubdtype(all_df[c].dtype, np.number)
    ]
    all_df = all_df[keep].sort_values(['battery_id','cycle_index']).reset_index(drop=True)
    return all_df

# ---------- åˆ’åˆ† ----------
def train_val_test_split_grouped(battery_ids: List[str], ratios=(0.7,0.15,0.15), seed=SEED):
    rng = random.Random(seed)
    ids = sorted(set(battery_ids))
    rng.shuffle(ids)
    n = len(ids); n_tr = int(n*ratios[0]); n_va = int(n*ratios[1])
    train_ids = ids[:n_tr]
    val_ids   = ids[n_tr:n_tr+n_va]
    test_ids  = ids[n_tr+n_va:]
    return train_ids, val_ids, test_ids

# ---------- y ç›®æ ‡ ----------
# ç›®æ ‡åˆ—è‡ªåŠ¨/å¯é…ç½®ç”Ÿæˆï¼Œé¿å…ç¼ºå¤±å¯¼è‡´æŠ¥é”™
# é€‰æ‹©ä¸€ç§ï¼š
#   TARGET_MODE = 'auto'              -> è‡ªåŠ¨æ£€æµ‹ï¼Œä¼˜å…ˆå·²æœ‰ y/SOH/RULï¼›å¦åˆ™ä»å®¹é‡åˆ—ä¼°ç®— SOH
#   TARGET_MODE = 'column'            -> ç›´æ¥ä½¿ç”¨ä½ æŒ‡å®šçš„åˆ—å TARGET_COLUMN
#   TARGET_MODE = 'soh_from_capacity' -> ä»å®¹é‡åˆ—ä¼°ç®— SOHï¼ˆcap / æ¯ç”µæ± é¦–ä¸‰å¾ªç¯ä¸­ä½å®¹é‡ï¼‰
#   TARGET_MODE = 'rul_from_eol'      -> ä¼°ç®— RULï¼ˆéœ€è¦ EOL å‘¨æœŸåˆ—æˆ–åŸºäº SOH<é˜ˆå€¼æ¨æ–­ï¼‰
TARGET_MODE = 'auto'
TARGET_COLUMN = 'y'  # å½“ TARGET_MODE='column' æ—¶ç”Ÿæ•ˆ
CAPACITY_COL_CANDIDATES = [
    'Capacity','capacity','Q_d','Qd','Q_discharge','discharge_capacity',
    'discharge_cap','Q','Ah','mAh','Capacity (mAh)','Discharge_Capacity'
]
EOL_CYCLE_COL = None      # å¦‚æœä½ æœ‰æ¯ç”µæ±  EOL å‘¨æœŸåˆ—ï¼Œå¡«åˆ—åï¼›å¦åˆ™ç•™ None
EOL_SOH_THRESHOLD = 0.8   # å½“åŸºäº SOH æ¨æ–­ EOL æ—¶ä½¿ç”¨


def _find_first_existing(df: pd.DataFrame, names: list) -> str | None:
    for n in names:
        if n in df.columns:
            return n
    return None


def _guess_capacity_col(df: pd.DataFrame) -> str | None:
    # åœ¨å€™é€‰+åŒ…å«å…³é”®å­—çš„åˆ—é‡Œé€‰æ–¹å·®æœ€å¤§çš„æ•°å€¼åˆ—
    cand = [c for c in df.columns if c in CAPACITY_COL_CANDIDATES]
    if not cand:
        # å®½æ¾å…³é”®å­—
        for c in df.columns:
            low = c.lower()
            if any(k in low for k in ['cap','qd','discharge']):
                cand.append(c)
    cand = [c for c in cand if np.issubdtype(df[c].dtype, np.number)]
    if not cand:
        return None
    var = {c: np.nanvar(pd.to_numeric(df[c], errors='coerce')) for c in cand}
    return max(var, key=var.get)


def _soh_from_capacity(df: pd.DataFrame, cap_col: str) -> pd.Series:
    # æ¯ç”µæ± é¦–ä¸‰å¾ªç¯ä¸­ä½å®¹é‡ä½œä¸ºåŸºçº¿
    def _per_batt(g: pd.DataFrame) -> pd.Series:
        g = g.sort_values('cycle_index')
        base = pd.to_numeric(g[cap_col], errors='coerce').head(3).median()
        soh = pd.to_numeric(g[cap_col], errors='coerce') / (base if base and np.isfinite(base) and base!=0 else 1.0)
        return soh.clip(lower=0.0, upper=1.2)
    return df.groupby('battery_id', group_keys=False).apply(_per_batt)


def _rul_from_eol(df: pd.DataFrame, cap_col: str | None) -> pd.Series:
    if EOL_CYCLE_COL and EOL_CYCLE_COL in df.columns:
        eol_map = df.groupby('battery_id')[EOL_CYCLE_COL].max().to_dict()
    else:
        # é€šè¿‡ SOH æ¨æ–­ EOL
        if cap_col is None:
            cap_col = _guess_capacity_col(df)
        if cap_col is None:
            raise ValueError("æ— æ³•æ ¹æ®å®¹é‡æ¨æ–­ EOLï¼šæ‰¾ä¸åˆ°å®¹é‡ç›¸å…³åˆ—ã€‚è¯·è®¾ç½® EOL_CYCLE_COL æˆ–æä¾›å®¹é‡åˆ—/æ”¹ç”¨ SOHã€‚")
        soh = _soh_from_capacity(df, cap_col)
        # æ¯ç”µæ± ç¬¬ä¸€ä¸ªä½äºé˜ˆå€¼çš„å¾ªç¯ä½œä¸º EOL
        eol_map = {}
        for bid, g in df.assign(_soh=soh).groupby('battery_id'):
            below = g[g['_soh'] < EOL_SOH_THRESHOLD]['cycle_index']
            eol = int(below.iloc[0]) if len(below) else int(g['cycle_index'].max())
            eol_map[bid] = eol
    # RUL = EOL - å½“å‰ cycle_index
    rul = df.apply(lambda r: max(0, int(eol_map.get(r['battery_id'], r['cycle_index'])) - int(r['cycle_index'])), axis=1)
    return pd.to_numeric(rul, errors='coerce')


def compute_target(df: pd.DataFrame) -> pd.Series:
    # 1) ç›´æ¥ä½¿ç”¨å·²æœ‰åˆ—
    if TARGET_MODE == 'column':
        if TARGET_COLUMN not in df.columns:
            raise ValueError(f"ç›®æ ‡åˆ— {TARGET_COLUMN} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ TARGET_COLUMN æˆ–åˆ‡æ¢ TARGET_MODE")
        return pd.to_numeric(df[TARGET_COLUMN], errors='coerce')

    if TARGET_MODE == 'auto':
        for name in ['y','SOH','soh','RUL','rul']:
            if name in df.columns:
                return pd.to_numeric(df[name], errors='coerce')
        cap_col = _guess_capacity_col(df)
        if cap_col is not None:
            print(f"[info] AUTO: ä¾æ®å®¹é‡åˆ— '{cap_col}' ä¼°ç®— SOH ä½œä¸º y")
            return _soh_from_capacity(df, cap_col)
        raise ValueError("AUTO æ¨¡å¼ä¸‹ï¼šæœªæ‰¾åˆ° y/SOH/RULï¼Œä¸”æ— æ³•è¯†åˆ«å®¹é‡åˆ—ä»¥ä¼°ç®— SOHã€‚è¯·è®¾ç½® TARGET_MODE å’Œç›¸å…³å‚æ•°ã€‚")

    if TARGET_MODE == 'soh_from_capacity':
        cap_col = _find_first_existing(df, CAPACITY_COL_CANDIDATES) or _guess_capacity_col(df)
        if cap_col is None:
            raise ValueError("soh_from_capacityï¼šæ‰¾ä¸åˆ°å®¹é‡åˆ—ï¼ˆå¯åœ¨ CAPACITY_COL_CANDIDATES ä¸­æ·»åŠ ä½ æ•°æ®çš„åˆ—åï¼‰")
        return _soh_from_capacity(df, cap_col)

    if TARGET_MODE == 'rul_from_eol':
        cap_col = _guess_capacity_col(df)
        return _rul_from_eol(df, cap_col)

    raise ValueError("æœªçŸ¥ TARGET_MODEï¼Œè¯·ä½¿ç”¨ 'auto' / 'column' / 'soh_from_capacity' / 'rul_from_eol'")

# ---------- å½’ä¸€åŒ– ----------
def fit_minmax(df_train: pd.DataFrame, feature_cols: List[str]) -> Dict[str, Dict[str,float]]:
    stats = {}
    for c in feature_cols:
        s = pd.to_numeric(df_train[c], errors='coerce')
        mn, mx = float(np.nanmin(s)), float(np.nanmax(s))
        if not np.isfinite(mn) or not np.isfinite(mx) or mn == mx:
            stats[c] = {"min": float(mn if np.isfinite(mn) else 0.0),
                        "max": float((mn if np.isfinite(mn) else 0.0) + 1.0)}
        else:
            stats[c] = {"min": mn, "max": mx}
    return stats

def apply_minmax(df: pd.DataFrame, feature_cols: List[str], stats: Dict[str, Dict[str,float]]) -> pd.DataFrame:
    out = df.copy()
    for c in feature_cols:
        a, b = stats[c]["min"], stats[c]["max"]
        denom = (b-a) if (b-a) != 0 else 1.0
        out[c] = (pd.to_numeric(out[c], errors='coerce') - a) / denom
    return out

# ---------- MD åˆç­› ----------
def mean_deviation_filter(df_train: pd.DataFrame, feature_cols: List[str], thr: float) -> List[str]:
    keep = []
    for c in feature_cols:
        s = pd.to_numeric(df_train[c], errors='coerce')
        md = float((s - s.mean()).abs().mean())
        if np.isfinite(md) and md > thr:
            keep.append(c)
    return keep

# ---------- Null-Importance ----------
def lgb_feature_importance(train_X: pd.DataFrame, train_y: np.ndarray, params: dict, seed: int) -> pd.Series:
    dtrain = lgb.Dataset(train_X, label=train_y, free_raw_data=True)
    local = params.copy(); local["seed"] = seed
    model = lgb.train(
        params=local,
        train_set=dtrain,
        num_boost_round=NUM_BOOST_ROUND,
        valid_sets=[dtrain],
        callbacks=[lgb.log_evaluation(period=0)]  # é™é»˜
    )
    imp = pd.Series(model.feature_importance(importance_type='gain'), index=train_X.columns)
    return imp

def null_importance_selection(train_X: pd.DataFrame, train_y: np.ndarray, params: dict,
                              n_real: int, n_null: int, seed: int) -> pd.DataFrame:
    rng = np.random.RandomState(seed)
    real_imps = []
    for i in range(n_real):
        imp = lgb_feature_importance(train_X, train_y, params, seed + i)
        real_imps.append(imp)
    real = pd.concat(real_imps, axis=1).fillna(0.0)
    real_mean = real.mean(axis=1)

    null_imps = []
    for j in range(n_null):
        y_perm = train_y.copy()
        rng.shuffle(y_perm)
        imp = lgb_feature_importance(train_X, y_perm, params, seed + 100 + j)
        null_imps.append(imp)
    null = pd.concat(null_imps, axis=1).fillna(0.0)
    null_mean = null.mean(axis=1)

    # ç»Ÿè®¡é‡ï¼šimp_ratio + è¿‘ä¼¼ p-value
    eps = 1e-12
    imp_ratio = (real_mean + eps) / (null_mean + eps)
    # p_value â‰ˆ null > real çš„é¢‘ç‡
    p_counts = (null.values > real_mean.values.reshape(-1,1)).sum(axis=1)
    p_value = (p_counts + 1.0) / (null.shape[1] + 1.0)

    out = pd.DataFrame({
        "feature": real_mean.index,
        "real_mean": real_mean.values,
        "null_mean": null_mean.reindex(real_mean.index).values,
        "imp_ratio": imp_ratio.values,
        "p_value": p_value.values
    }).sort_values("imp_ratio", ascending=False).reset_index(drop=True)
    return out

# ---------- Spearman ----------
def spearman_ranking(train_df: pd.DataFrame, feature_cols: List[str], y_col: str) -> pd.DataFrame:
    rhos = []
    y = train_df[y_col].values
    for c in feature_cols:
        x = pd.to_numeric(train_df[c], errors='coerce').values
        if np.all(~np.isfinite(x)) or np.nanstd(x) == 0:
            rho = 0.0
        else:
            rho, _ = spearmanr(x, y, nan_policy='omit')
            if not np.isfinite(rho):
                rho = 0.0
        rhos.append((c, abs(float(rho))))
    out = pd.DataFrame(rhos, columns=["feature","abs_spearman"]) \
            .sort_values("abs_spearman", ascending=False).reset_index(drop=True)
    return out

# ---------- æ¯ç”µæ± ç­›é€‰ä¸»å‡½æ•° ----------
def select_features_for_one_battery(df_batt_n: pd.DataFrame, feature_cols_numeric: List[str], y_col: str = "y") -> Tuple[List[str], pd.DataFrame, pd.DataFrame]:
    # 1) MD åˆç­›ï¼ˆè¯¥ç”µæ± å½’ä¸€åŒ–æ•°æ®ï¼‰
    md_keep = mean_deviation_filter(df_batt_n, feature_cols_numeric, MD_THRESHOLD)

    # 2) Null-importanceï¼ˆè¯¥ç”µæ± è‡ªå·±çš„æ ·æœ¬ä¸æ ‡ç­¾ï¼‰â€”â€”ä¸¥æ ¼é˜ˆå€¼è´´è¿‘è®ºæ–‡
    train_X = df_batt_n[md_keep].copy()
    train_y = pd.to_numeric(df_batt_n[y_col], errors='coerce').values.astype(float)
    if train_X.shape[1] == 0:
        return [], pd.DataFrame(columns=["feature","imp_ratio","p_value"]), pd.DataFrame(columns=["feature","abs_spearman"])

    ni_table = null_importance_selection(train_X, train_y, LGB_PARAMS,
                                         N_REAL_RUNS, N_NULL_RUNS, SEED)
    ni_keep = ni_table[(ni_table['imp_ratio'] > 1.0) & (ni_table['p_value'] <= 0.2)]['feature'].tolist()
    if not ni_keep:
        # å…œåº•ï¼šè‡³å°‘ç»™å‡ºè‹¥å¹²å€™é€‰ï¼Œä¿è¯åç»­ Spearman å¯æ‰§è¡Œ
        ni_keep = ni_table.head(min(10, len(ni_table)))['feature'].tolist()

    # 3) Spearman æ’åº/æˆªæ–­
    sp_table = spearman_ranking(df_batt_n, ni_keep, y_col)
    if len(sp_table):
        if SPEARMAN_KEEP_TOPK < len(sp_table):
            sp_keep = sp_table.head(SPEARMAN_KEEP_TOPK)['feature'].tolist()
        else:
            q = SPEARMAN_KEEP_QUANTILE
            cut = sp_table['abs_spearman'].quantile(q)
            sp_keep = sp_table[sp_table['abs_spearman'] >= cut]['feature'].tolist()
    else:
        sp_keep = ni_keep

    return sp_keep, ni_table, sp_table

# ---------- å›¾è¡¨é£æ ¼ ----------
def setup_paper_style():
    mpl.rcParams.update({
        'font.family': FIG_FONT_FAMILY,
        'font.size': 9,
        'axes.titlesize': 10,
        'axes.labelsize': 9,
        'xtick.labelsize': 8,
        'ytick.labelsize': 8,
        'legend.fontsize': 8,
        'axes.linewidth': 0.8,
        'grid.linewidth': 0.6,
        'lines.linewidth': 1.2,
        'savefig.dpi': FIG_DPI,
        'pdf.fonttype': 42,   # TrueTypeï¼Œé¿å…åµŒå…¥ Type3
        'ps.fonttype': 42
    })

# ---------- ç”»å›¾ ----------
def plot_feature_frequency(freq_series: pd.Series, out_path: str, top_n: int = 30):
    setup_paper_style()
    s = freq_series.sort_values(ascending=False).head(top_n)
    fig = plt.figure(figsize=(FIG_W_SINGLE, FIG_H_BAR))
    ax = fig.add_subplot(111)
    bars = ax.bar(range(len(s)), s.values, color='white', edgecolor='black', linewidth=0.8)
    # æ–œä½“/ç«–æ’æ ‡ç­¾ï¼šæ—‹è½¬ 60Â°ï¼Œç´§å‡‘æ’ç‰ˆ
    ax.set_xticks(range(len(s)))
    ax.set_xticklabels(s.index, rotation=60, ha='right')
    ax.set_ylabel('Frequency')
    ax.set_title('Feature selection frequency (train batteries)')
    # ä¸Šè¾¹æ¡†å»æ‰é¢œè‰²ä»¥ç®€æ´
    for spine in ['top']:
        ax.spines[spine].set_visible(False)
    fig.tight_layout()
    fig.savefig(out_path, bbox_inches='tight')
    plt.close(fig)


def plot_selection_matrix(binary_df: pd.DataFrame, out_path: str):
    setup_paper_style()
    fig = plt.figure(figsize=(FIG_W_SINGLE, FIG_H_HEAT))
    ax = fig.add_subplot(111)
    # ç°åº¦çƒ­å›¾ï¼š1=é»‘ï¼Œ0=ç™½
    mat = binary_df.values.astype(float)
    im = ax.imshow(mat, cmap='Greys', aspect='auto', interpolation='nearest', vmin=0, vmax=1)
    ax.set_yticks(range(binary_df.shape[0]))
    ax.set_yticklabels(binary_df.index)
    ax.set_xticks(range(binary_df.shape[1]))
    ax.set_xticklabels(binary_df.columns, rotation=60, ha='right')
    ax.set_xlabel('Features')
    ax.set_ylabel('Batteries (train)')
    ax.set_title('Per-battery selected features (binary)')
    fig.tight_layout()
    fig.savefig(out_path, bbox_inches='tight')
    plt.close(fig)

# ---------- ä¸»æµç¨‹ ----------
def main():
    random.seed(SEED); np.random.seed(SEED)
    os.makedirs(OUT_DIR, exist_ok=True)
    os.makedirs(os.path.join(OUT_DIR, 'reports'), exist_ok=True)
    os.makedirs(os.path.join(OUT_DIR, 'figs'), exist_ok=True)

    # 1) è¯»å…¥åˆå¹¶ç‰¹å¾
    all_df = load_all_combined(COMBINED_DIR)

    # 2) ç›®æ ‡åˆ—ï¼ˆè‹¥å·²æœ‰ y åˆ—ç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™åœ¨ compute_target ä¸­è‡ªå®šä¹‰ï¼‰
    all_df = all_df.copy()
    all_df['y'] = compute_target(all_df)

    # 3) ç”µæ± åˆ†å±‚åˆ’åˆ†
    battery_ids = all_df['battery_id'].unique().tolist()
    train_ids, val_ids, test_ids = train_val_test_split_grouped(battery_ids)

    df_train = all_df[all_df['battery_id'].isin(train_ids)].reset_index(drop=True)
    df_val   = all_df[all_df['battery_id'].isin(val_ids)].reset_index(drop=True)
    df_test  = all_df[all_df['battery_id'].isin(test_ids)].reset_index(drop=True)

    feature_cols_numeric = [c for c in all_df.columns if c not in ['battery_id','cycle_index','y']]

    # 4) ä»…ç”¨è®­ç»ƒé›†æ‹Ÿåˆ MinMaxï¼Œå¹¶åº”ç”¨åˆ°å…¨é‡
    scaler = fit_minmax(df_train, feature_cols_numeric)
    with open(os.path.join(OUT_DIR, "minmax_scaler.json"), "w", encoding="utf-8") as f:
        json.dump(scaler, f, ensure_ascii=False, indent=2)

    df_train_n = apply_minmax(df_train, feature_cols_numeric, scaler)
    df_val_n   = apply_minmax(df_val,   feature_cols_numeric, scaler)
    df_test_n  = apply_minmax(df_test,  feature_cols_numeric, scaler)

    # 5) æ¯ç”µæ± ç‹¬ç«‹ç­›é€‰ï¼ˆä»…è®­ç»ƒé›†ï¼‰
    per_batt_selected: Dict[str, List[str]] = {}
    per_batt_spearman: Dict[str, pd.DataFrame] = {}

    for bid, g_train in df_train_n.groupby('battery_id'):
        feats, ni_tab, sp_tab = select_features_for_one_battery(
            g_train, feature_cols_numeric, y_col='y')
        per_batt_selected[bid] = feats
        per_batt_spearman[bid] = sp_tab
        # ä¿å­˜æŠ¥å‘Š
        ni_tab.to_csv(os.path.join(OUT_DIR, 'reports', f'{bid}_null_importance.csv'), index=False, encoding='utf-8-sig')
        sp_tab.to_csv(os.path.join(OUT_DIR, 'reports', f'{bid}_spearman.csv'), index=False, encoding='utf-8-sig')

    with open(os.path.join(OUT_DIR, 'features_selected_per_battery.json'), 'w', encoding='utf-8') as f:
        json.dump(per_batt_selected, f, ensure_ascii=False, indent=2)

    # 6) é¢‘æ¬¡ç»Ÿè®¡ + æ‰“ç ´å¹¶åˆ—ï¼ˆå…¨å±€ |rho| çš„å¹³å‡ï¼‰
    # é¢‘æ¬¡
    freq = {}
    for bid, feats in per_batt_selected.items():
        for c in feats:
            freq[c] = freq.get(c, 0) + 1
    freq_ser = pd.Series(freq).sort_values(ascending=False)

    # æ‰“ç ´å¹¶åˆ—ï¼šå„ç”µæ±  Spearman çš„ |rho| å¹³å‡å€¼
    rho_mean = {}
    for c in freq_ser.index:
        vals = []
        for bid, sp_tab in per_batt_spearman.items():
            row = sp_tab[sp_tab['feature'] == c]
            if not row.empty:
                vals.append(float(row['abs_spearman'].iloc[0]))
        rho_mean[c] = float(np.mean(vals)) if len(vals) else 0.0
    rho_ser = pd.Series(rho_mean)

    # æœ€ç»ˆæ’åºï¼šå…ˆæŒ‰é¢‘æ¬¡é™åºï¼Œå†æŒ‰ rho_mean é™åº
    order_df = pd.DataFrame({'feature': freq_ser.index, 'freq': freq_ser.values})
    order_df['rho_mean'] = order_df['feature'].map(rho_ser)
    order_df = order_df.sort_values(['freq','rho_mean'], ascending=[False, False]).reset_index(drop=True)

    final_features = order_df['feature'].head(FINAL_TOP_K).tolist()
    with open(os.path.join(OUT_DIR, 'features_final_global.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'final_features': final_features,
            'frequency_table': order_df.to_dict(orient='list')
        }, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“Œ æœ€ç»ˆå…¨å±€ç‰¹å¾ Top-{FINAL_TOP_K}: {final_features}")

    # 7) å¯¼å‡ºç»Ÿä¸€åˆ—çš„ tabular_*.csvï¼ˆè®ºæ–‡å¼ï¼šåªä¿ç•™æœ€ç»ˆå…¨å±€ç‰¹å¾ï¼‰
    def export(df_split_n: pd.DataFrame, name: str):
        cols = ['battery_id','cycle_index'] + final_features + ['y']
        # å¯¹å¯èƒ½ç¼ºå¤±çš„åˆ—è¡¥é½ï¼ˆæ²¡æœ‰çš„ç½®ä¸º NaNâ†’0.0ï¼‰
        tmp = df_split_n.copy()
        for c in final_features:
            if c not in tmp.columns:
                tmp[c] = np.nan
        out = tmp[cols].copy()
        out[final_features] = out[final_features].fillna(0.0)
        out.to_csv(os.path.join(OUT_DIR, f'tabular_{name}.csv'), index=False, encoding='utf-8-sig', float_format='%.10g')
        print(f"âœ… å¯¼å‡º {name}: {out.shape} -> {os.path.join(OUT_DIR, f'tabular_{name}.csv')}")

    export(df_train_n, 'train')
    export(df_val_n,   'val')
    export(df_test_n,  'test')

    # 8) ä½œå›¾ï¼ˆè®ºæ–‡é£æ ¼ï¼‰
    plot_feature_frequency(freq_ser, os.path.join(OUT_DIR, 'figs', 'feature_frequency_bar.png'), top_n=min(30, len(freq_ser)))

    # é€‰æ‹©çŸ©é˜µï¼ˆä»…ç”¨æœ€ç»ˆç‰¹å¾ï¼‰
    # è¡Œï¼šè®­ç»ƒç”µæ± ï¼Œåˆ—ï¼šfinal_features
    mat = []
    idx = []
    for bid in sorted(per_batt_selected.keys()):
        idx.append(bid)
        s = pd.Series(0, index=final_features, dtype=int)
        for c in per_batt_selected[bid]:
            if c in s.index:
                s[c] = 1
        mat.append(s)
    if len(mat):
        binary_df = pd.DataFrame(mat, index=idx, columns=final_features)
        plot_selection_matrix(binary_df, os.path.join(OUT_DIR, 'figs', 'selection_matrix_heatmap.png'))

    print("ğŸ¯ å®Œæˆï¼šæ¯ç”µæ± ç­›é€‰ + é¢‘æ¬¡ç»Ÿè®¡ + è®ºæ–‡é£æ ¼å›¾ ä¸ æ•°æ®é›†å¯¼å‡ºã€‚")


if __name__ == "__main__":
    main()
