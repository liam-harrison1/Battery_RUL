# -*- coding: utf-8 -*-
"""
å…¥æ¨¡å‰å‡†å¤‡ + ä¸¤çº§ç­›é€‰ï¼ˆMean-Deviation + Null-Importance + Spearmanï¼‰
- è¾“å…¥ï¼šä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„ *_combined_features.csvï¼ˆæ¯ç”µæ± /æ¯å¾ªç¯ä¸€è¡Œï¼‰
- è¾“å‡ºï¼štabular_train/val/test.csvï¼ˆå« battery_id, cycle_index, é€‰ä¸­ç‰¹å¾, yï¼‰
      ä»¥åŠï¼šminmax_scaler.jsonã€features_selected.jsonã€
            null_importance_report.csvã€spearman_report.csv

âœ… æœ¬ç‰ˆä¿®å¤ï¼š
- LightGBM 4.x ç§»é™¤ verbose_evalï¼šæ”¹ç”¨ callbacks=[lgb.log_evaluation(period=0)]
- å‚æ•° verbose â†’ verbosity
"""

import os, re, json, random, gc
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple
from scipy.stats import spearmanr
import lightgbm as lgb

# ========== é…ç½® ==========
COMBINED_DIR = r"C:\Users\13512\Desktop\features_mixed"  # æ”¹æˆä½ çš„ *_combined_features.csv æ‰€åœ¨ç›®å½•
OUT_DIR      = r"C:\Users\13512\Desktop\final_dataset_10features"           # è¾“å‡ºç›®å½•
TARGET_MODE  = "rul"    # 'rul' æˆ– 'capacity_ratio'
SPLIT_RATIO  = (0.7, 0.15, 0.15)  # Train/Val/Test æŒ‰â€œç”µæ± â€åˆ’åˆ†
SEED         = 42

# å‡å€¼åå·®åˆç­›é˜ˆå€¼ï¼ˆåœ¨ MinMax ä¹‹åï¼‰
MD_THRESHOLD = 1e-8

# Null-importance å‚æ•°ï¼ˆå¯å…ˆå°ä¸€ç‚¹åŠ é€Ÿè¯•è·‘ï¼‰
N_REAL_RUNS  = 20     # çœŸæ ‡ç­¾è·‘å‡ æ¬¡
N_NULL_RUNS  = 20     # ä¹±åºæ ‡ç­¾è·‘å‡ æ¬¡
NUM_BOOST_ROUND = 600 # æ¯æ¬¡ LightGBM è¿­ä»£è½®æ•°

LGB_PARAMS = dict(
    objective="regression",
    metric="mae",
    learning_rate=0.03,
    num_leaves=64,
    min_data_in_leaf=40,
    feature_fraction=0.8,
    bagging_fraction=0.8,
    bagging_freq=1,
    lambda_l1=0.0,
    lambda_l2=1.0,
    max_depth=-1,
    verbosity=-1,        # âœ… 4.x ç”¨ verbosity
    num_threads=0        # 0=ç”¨å°½å¯èƒ½å¤šçš„æ ¸ï¼›å¦‚éœ€é™æ ¸å¯æ”¹æˆå…·ä½“æ•°å­—
)

# Spearmanï¼šä¿ç•™ |rho| æ’åå‰ q åˆ†ä½ä»¥ä¸Š
SPEARMAN_KEEP_QUANTILE = 0


# ========== å·¥å…·å‡½æ•° ==========
def list_csv(dirp: str) -> List[str]:
    return [os.path.join(dirp, f) for f in os.listdir(dirp) if f.lower().endswith(".csv")]

def extract_battery_id_from_combined(path: str) -> str:
    # e.g. EL150800460436_combined_features.csv -> EL150800460436
    return os.path.basename(path).replace("_combined_features.csv", "")

def load_all_combined(combined_dir: str) -> pd.DataFrame:
    rows = []
    for fp in list_csv(combined_dir):
        if not fp.endswith("_combined_features.csv"):
            continue
        bid = extract_battery_id_from_combined(fp)
        df = pd.read_csv(fp)
        if 'cycle_index' not in df.columns:
            raise ValueError(f"{fp} ç¼ºå°‘ cycle_index åˆ—")
        df.insert(0, 'battery_id', bid)
        rows.append(df)
    if not rows:
        raise RuntimeError("æœªåœ¨ COMBINED_DIR ä¸­æ‰¾åˆ° *_combined_features.csv")
    all_df = pd.concat(rows, axis=0, ignore_index=True)
    # åªä¿ç•™æ•°å€¼åˆ— + ä¸»é”®
    keep = ['battery_id', 'cycle_index'] + [
        c for c in all_df.columns
        if c not in ('battery_id', 'cycle_index') and np.issubdtype(all_df[c].dtype, np.number)
    ]
    all_df = all_df[keep].sort_values(['battery_id','cycle_index']).reset_index(drop=True)
    return all_df

def train_val_test_split_grouped(battery_ids: List[str], ratios=(0.7,0.15,0.15), seed=42):
    rng = random.Random(seed)
    ids = sorted(battery_ids)
    rng.shuffle(ids)
    n = len(ids); n_tr = int(n*ratios[0]); n_va = int(n*ratios[1])
    train_ids = ids[:n_tr]
    val_ids   = ids[n_tr:n_tr+n_va]
    test_ids  = ids[n_tr+n_va:]
    return train_ids, val_ids, test_ids

def compute_target(df_one_batt: pd.DataFrame, mode: str) -> pd.Series:
    if mode == 'rul':
        m = int(df_one_batt['cycle_index'].max())
        return m - df_one_batt['cycle_index']
    elif mode == 'capacity_ratio':
        cand = [c for c in df_one_batt.columns if c.lower() in ('qd_ah','direct_qd_ah')]
        if not cand:
            raise ValueError("æœªæ‰¾åˆ° qd_ah/direct_qd_ah åˆ—ï¼Œæ— æ³•è®¡ç®— capacity_ratioã€‚å¯æ”¹ TARGET_MODE='rul'")
        q = pd.to_numeric(df_one_batt[cand[0]], errors='coerce')
        q0 = float(q.iloc[0]) if np.isfinite(q.iloc[0]) else float(np.nanmedian(q))
        if not np.isfinite(q0) or q0 == 0:
            raise ValueError("åˆå§‹å®¹é‡æ— æ•ˆï¼Œæ— æ³•è®¡ç®— capacity_ratio")
        return q / q0
    else:
        raise ValueError("TARGET_MODE ä»…æ”¯æŒ 'rul' æˆ– 'capacity_ratio'")

def fit_minmax(train_df: pd.DataFrame, feature_cols: List[str]) -> Dict[str, Dict[str,float]]:
    stats = {}
    for c in feature_cols:
        s = pd.to_numeric(train_df[c], errors='coerce')
        mn, mx = float(np.nanmin(s)), float(np.nanmax(s))
        if not np.isfinite(mn) or not np.isfinite(mx) or mn == mx:
            stats[c] = {"min": float(mn if np.isfinite(mn) else 0.0),
                        "max": float((mn if np.isfinite(mn) else 0.0) + 1.0)}
        else:
            stats[c] = {"min": mn, "max": mx}
    return stats

def apply_minmax(df: pd.DataFrame, feature_cols: List[str], stats: Dict[str, Dict[str,float]]) -> pd.DataFrame:
    out = df.copy()
    for c in feature_cols:
        a, b = stats[c]["min"], stats[c]["max"]
        denom = (b-a) if (b-a) != 0 else 1.0
        out[c] = (pd.to_numeric(out[c], errors='coerce') - a) / denom
    return out

def mean_deviation_filter(df_train: pd.DataFrame, feature_cols: List[str], thr: float) -> List[str]:
    keep = []
    for c in feature_cols:
        s = pd.to_numeric(df_train[c], errors='coerce')
        md = float((s - s.mean()).abs().mean())
        if np.isfinite(md) and md > thr:
            keep.append(c)
    return keep

# ====== LightGBM 4.xï¼šæ—  verbose_evalï¼Œç”¨ callbacks æ§åˆ¶æ—¥å¿— ======
def lgb_feature_importance(train_X: pd.DataFrame, train_y: np.ndarray, params: dict, seed: int) -> pd.Series:
    dtrain = lgb.Dataset(train_X, label=train_y, free_raw_data=True)
    local = params.copy(); local["seed"] = seed
    model = lgb.train(
        local,
        dtrain,
        num_boost_round=NUM_BOOST_ROUND,
        callbacks=[lgb.log_evaluation(period=0)]  # å…³é—­è®­ç»ƒæ—¥å¿—
    )
    imp = pd.Series(model.feature_importance(importance_type="gain"), index=train_X.columns)
    total = imp.sum()
    return (imp/total) if total > 0 else imp

def null_importance_selection(train_X: pd.DataFrame, train_y: np.ndarray,
                              params: dict, n_real: int, n_null: int, seed: int) -> pd.DataFrame:
    rng = np.random.RandomState(seed)

    # çœŸæ ‡ç­¾å¤šæ¬¡
    real_imps = []
    for i in range(n_real):
        imp = lgb_feature_importance(train_X, train_y, params, seed + i)
        real_imps.append(imp)
    real_df = pd.concat(real_imps, axis=1).fillna(0.0)
    real_mean = real_df.mean(axis=1)

    # ä¹±åºæ ‡ç­¾å¤šæ¬¡
    null_imps = []
    for j in range(n_null):
        y_shuf = train_y.copy(); rng.shuffle(y_shuf)
        imp = lgb_feature_importance(train_X, y_shuf, params, seed + 1000 + j)
        null_imps.append(imp)
    null_df = pd.concat(null_imps, axis=1).fillna(0.0)
    null_mean = null_df.mean(axis=1)

    eps = 1e-9
    imp_ratio = (real_mean + eps) / (null_mean + eps)
    # p_valueï¼šæœ‰å¤šå°‘ null å‡å€¼ >= çœŸå‡å€¼
    p_value = (null_df.T >= real_mean.values).mean(axis=0)

    out = pd.DataFrame({
        "feature": real_mean.index,
        "real_mean": real_mean.values,
        "null_mean": null_mean.reindex(real_mean.index).values,
        "imp_ratio": imp_ratio.values,
        "p_value": p_value.values
    }).sort_values("imp_ratio", ascending=False).reset_index(drop=True)
    return out

def spearman_ranking(train_df: pd.DataFrame, feature_cols: List[str], y_col: str) -> pd.DataFrame:
    rhos = []
    y = train_df[y_col].values
    for c in feature_cols:
        x = pd.to_numeric(train_df[c], errors='coerce').values
        if np.all(~np.isfinite(x)) or np.nanstd(x) == 0:
            rho = 0.0
        else:
            rho, _ = spearmanr(x, y, nan_policy='omit')
            if not np.isfinite(rho): rho = 0.0
        rhos.append((c, abs(float(rho))))
    out = pd.DataFrame(rhos, columns=["feature","abs_spearman"]).sort_values("abs_spearman", ascending=False)
    return out


# ========== ä¸»æµç¨‹ ==========
def main():
    random.seed(SEED); np.random.seed(SEED)
    os.makedirs(OUT_DIR, exist_ok=True)

    # 1) è¯»å–å…¨éƒ¨ç”µæ± çš„åˆå¹¶ç‰¹å¾
    all_df = load_all_combined(COMBINED_DIR)
    feature_cols_all = [c for c in all_df.columns if c not in ('battery_id','cycle_index')]
    print(f"è½½å…¥å®Œæˆï¼š{len(all_df['battery_id'].unique())} ä¸ªç”µæ± ï¼Œ{len(all_df)} æ¡å¾ªç¯ï¼›å€™é€‰ç‰¹å¾ {len(feature_cols_all)} åˆ—")

    # 2) è®¡ç®—æ ‡ç­¾ yï¼ˆæŒ‰ç”µæ± ï¼‰
    parts = []
    for bid, g in all_df.groupby('battery_id'):
        g = g.sort_values('cycle_index').reset_index(drop=True).copy()
        g['y'] = compute_target(g, TARGET_MODE)
        parts.append(g)
    all_df = pd.concat(parts, axis=0, ignore_index=True)

    # 3) æŒ‰ç”µæ± åˆ†ç»„åˆ‡åˆ†
    train_ids, val_ids, test_ids = train_val_test_split_grouped(sorted(all_df['battery_id'].unique()), SPLIT_RATIO, SEED)
    df_train = all_df[all_df['battery_id'].isin(train_ids)].reset_index(drop=True)
    df_val   = all_df[all_df['battery_id'].isin(val_ids)].reset_index(drop=True)
    df_test  = all_df[all_df['battery_id'].isin(test_ids)].reset_index(drop=True)
    print(f"åˆ’åˆ†ï¼štrain={len(train_ids)} ç”µæ± , val={len(val_ids)}, test={len(test_ids)}")

    # 4) ä»…åœ¨è®­ç»ƒé›†æ‹Ÿåˆ Minâ€“Max å¹¶åº”ç”¨
    feature_cols_numeric = [c for c in feature_cols_all if np.issubdtype(all_df[c].dtype, np.number)]
    scaler = fit_minmax(df_train, feature_cols_numeric)
    with open(os.path.join(OUT_DIR, "minmax_scaler.json"), "w", encoding="utf-8") as f:
        json.dump(scaler, f, ensure_ascii=False, indent=2)

    df_train_n = apply_minmax(df_train, feature_cols_numeric, scaler)
    df_val_n   = apply_minmax(df_val,   feature_cols_numeric, scaler)
    df_test_n  = apply_minmax(df_test,  feature_cols_numeric, scaler)

    # 5) å‡å€¼åå·®åˆç­›ï¼ˆè®­ç»ƒé›†ï¼‰
    md_keep = mean_deviation_filter(df_train_n, feature_cols_numeric, MD_THRESHOLD)
    print(f"MD åˆç­›ï¼šä¿ç•™ {len(md_keep)}/{len(feature_cols_numeric)} åˆ—")

    # 6) Null-Importanceï¼ˆè®­ç»ƒé›†ï¼‰
    train_X = df_train_n[md_keep].copy()
    train_y = df_train_n['y'].values.astype(float)
    ni_table = null_importance_selection(train_X, train_y, LGB_PARAMS, N_REAL_RUNS, N_NULL_RUNS, SEED)
    # è§„åˆ™ï¼šimp_ratio > 1 ä¸” p_value <= 0.2
    ni_keep = ni_table[(ni_table['imp_ratio'] > 0.4) & (ni_table['p_value'] <= 0.7)]['feature'].tolist()
    print(f"Null-Importance é€šè¿‡ï¼š{len(ni_keep)} åˆ—")

    # 7) Spearman éªŒè¯ï¼ˆè®­ç»ƒé›†ï¼‰
    sp_table = spearman_ranking(df_train_n, ni_keep, 'y')
    if len(sp_table):
        cut = sp_table['abs_spearman'].quantile(SPEARMAN_KEEP_QUANTILE)
        sp_keep = sp_table[sp_table['abs_spearman'] >= cut]['feature'].tolist()
    else:
        cut = 1.0
        sp_keep = []
    print(f"Spearman é€šè¿‡ï¼š{len(sp_keep)} åˆ— (é˜ˆå€¼={cut:.4f})")

    selected_features = sp_keep
    with open(os.path.join(OUT_DIR, "features_selected.json"), "w", encoding="utf-8") as f:
        json.dump({"selected_features": selected_features}, f, ensure_ascii=False, indent=2)

    # 8) å¯¼å‡º Tabularï¼ˆä»…ä¿ç•™é€‰ä¸­ç‰¹å¾ï¼‰
    def export(df_in: pd.DataFrame, name: str):
        cols = ['battery_id','cycle_index'] + selected_features + ['y']
        out = df_in[cols].copy()
        out.to_csv(os.path.join(OUT_DIR, f"tabular_{name}.csv"),
                   index=False, encoding="utf-8-sig", float_format="%.10g")
        print(f"âœ… å¯¼å‡º {name}: {out.shape} -> {os.path.join(OUT_DIR, f'tabular_{name}.csv')}")

    export(df_train_n, "train")
    export(df_val_n,   "val")
    export(df_test_n,  "test")

    # 9) ä¿å­˜ç­›é€‰æŠ¥å‘Š
    ni_table.to_csv(os.path.join(OUT_DIR, "null_importance_report.csv"), index=False, encoding="utf-8-sig")
    sp_table.to_csv(os.path.join(OUT_DIR, "spearman_report.csv"), index=False, encoding="utf-8-sig")

    print("ğŸ¯ å®Œæˆï¼šç‰¹å¾ç™½åå•ä¸å½’ä¸€åŒ–æ•°æ®å·²å°±ç»ªï¼Œå¯ç›´æ¥å…¥æ¨¡ã€‚")

if __name__ == "__main__":
    main()
